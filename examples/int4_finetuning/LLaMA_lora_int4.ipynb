{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# [xTuring](https://github.com/stochasticai/xturing) - LLaMA INT4 efficient fine-tuning tutorial\n",
    "\n",
    "This tutorial aims to show how easy it is to perform fine-tuning with xTuring. This notebook shows how to fine-tune LLaMA 7B model on GPU which has limited memory, it requires only 6GB VRAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 1. Install the `xTuring` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!pip install xturing --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def pull_docker_image(image):\n",
    "    cmd = [\"docker\", \"pull\", image]\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "\n",
    "def run_docker_container(image, port_mapping, env_vars=None, gpus=None, volumes=None):\n",
    "    cmd = [\"docker\", \"container\", \"run\"]\n",
    "\n",
    "    if env_vars is None:\n",
    "        env_vars = {}\n",
    "\n",
    "    if volumes is None:\n",
    "        volumes = {}\n",
    "\n",
    "    if gpus is not None:\n",
    "        cmd.extend([\"--gpus\", gpus])\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        cmd.extend([\"-e\", f\"{key}={value}\"])\n",
    "\n",
    "    for local_path, container_path in volumes.items():\n",
    "        cmd.extend([\"-v\", f\"{str(Path(local_path).resolve())}:{container_path}\"])\n",
    "\n",
    "    cmd.extend([\"-p\", port_mapping, image])\n",
    "\n",
    "    subprocess.run(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load and run docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Install Docker on your machine if you haven't already. You can follow the [official Docker documentation](https://docs.docker.com/engine/install/) for installation instructions.\n",
    "2. Install NVIDIA Container Toolkit\n",
    "    ```bash\n",
    "    sudo apt-get install -y nvidia-docker2\n",
    "    ```\n",
    "3. Run the Docker daemon\n",
    "    ```bash\n",
    "    sudo systemctl start docker\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "image = \"public.ecr.aws/t8g5g2q5/xturing:int4_finetuning\"\n",
    "port_mapping = \"5000:5000\"\n",
    "env_vars = {\n",
    "    \"WANDB_MODE\": \"dryrun\",\n",
    "    \"MICRO_BATCH_SIZE\": \"1\", # change this to increase your micro batch size\n",
    "}\n",
    "# if you want to log results to wandb, set the following env var\n",
    "# env_vars = {\n",
    "#     \"WANDB_API_KEY\": \"<your_wandb_api_key>\",\n",
    "#     \"WANDB_PROJECT\": \"your_project_name\",\n",
    "#     \"WANDB_ENTITY\": \"your_entity_name\",\n",
    "#     # Add more environment variables as needed\n",
    "# }\n",
    "volumes = {\n",
    "    # \"<where to save model>\": \"/model\",\n",
    "    \"../llama/alpaca_data\": \"/data\", # change this to your data path if you want\n",
    "}\n",
    "gpus = \"all\"\n",
    "\n",
    "pull_docker_image(image)\n",
    "\n",
    "run_docker_container(image, port_mapping, env_vars, gpus, volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you prefer it, you can run the Docker container from the CLI using the following command:\n",
    "\n",
    "```bash\n",
    "docker run -p 5000:5000 --gpus all -e WANDB_MODE=dryrun -e MICRO_BATCH_SIZE=1 -v /absolute/path/to/alpaca/data:/data public.ecr.aws/t8g5g2q5/xturing:int4_finetuning\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
