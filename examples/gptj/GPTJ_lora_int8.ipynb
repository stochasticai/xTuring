{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# [xturing](https://github.com/stochasticai/xturing) - GPTJ efficient fine-tuning tutorial\n",
        "\n",
        "This tutorial aims to show how easy it is to perform fine-tuning with xturing. This notebook shows how to finetune GPTJ 6B model on GPU which has limited memory, it requires only 9GB Vram"
      ],
      "metadata": {
        "id": "PY9zeKVN277J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install the `xturing` library"
      ],
      "metadata": {
        "id": "KpQMdSLY3Cz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNFVFKld2Ju4"
      },
      "outputs": [],
      "source": [
        "!pip install xturing --upgrade"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Download and unzip the dataset"
      ],
      "metadata": {
        "id": "wONewxy63FnQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRO0TVPP2iFy"
      },
      "outputs": [],
      "source": [
        "!wget https://d33tr4pxdm6e2j.cloudfront.net/public_content/tutorials/datasets/alpaca_data.zip\n",
        "!unzip alpaca_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPXW1hQt3Jqp"
      },
      "outputs": [],
      "source": [
        "from xturing.datasets.instruction_dataset import InstructionDataset\n",
        "from xturing.models.base import BaseModel\n",
        "\n",
        "instruction_dataset = InstructionDataset(\"/content/alpaca_data\")\n",
        "# Initializes the model\n",
        "model = BaseModel.create(\"gptj_lora_int8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Load the dataset and initialize the model"
      ],
      "metadata": {
        "id": "aq-CQVD_3L-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwvVo7Sx2vVj"
      },
      "outputs": [],
      "source": [
        "from xturing.datasets.instruction_dataset import InstructionDataset\n",
        "from xturing.models.base import BaseModel\n",
        "\n",
        "instruction_dataset = InstructionDataset(\"/content/alpaca_data\")\n",
        "# Initializes the model\n",
        "model = BaseModel.create(\"llama_lora_int8\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Start the finetuning"
      ],
      "metadata": {
        "id": "xGhffX483P8r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHa8P_jM7jCx"
      },
      "outputs": [],
      "source": [
        "# Finetuned the model\n",
        "model.finetune(dataset=instruction_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYfFHtW33j4B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
