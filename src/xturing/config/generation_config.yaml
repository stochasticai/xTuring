# For large models contrastive search works very well.
# For smaller models top-p sampling is better. Contrastive search repeats the tokens in small models.


# Contrastive search
defaults:
  max_new_tokens: 256

# Contrastive search
bloom:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
bloom_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
bloom_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
bloom_int8:
  max_new_tokens: 256
  do_sample: false

# Contrastive search
cerebras:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
cerebras_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
cerebras_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
cerebras_int8:
  max_new_tokens: 256
  do_sample: false

# Top-p sampling
distilgpt2:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Top-p sampling
distilgpt2_lora:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Greedy search
falcon:
  max_new_tokens: 256
  do_sample: false

# Greedy search
falcon_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
falcon_lora:
  max_new_tokens: 256
  do_sample: false

# Greedy search
falcon_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
falcon_lora_kbit:
  max_new_tokens: 256
  do_sample: false

# Contrastive search
galactica:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
galactica_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
galactica_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
galactica_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
generic:
  max_new_tokens: 256
  do_sample: false

# Greedy search
generic_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
generic_lora:
  max_new_tokens: 256
  do_sample: false

# Greedy search
generic_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
generic_lora_kbit:
  max_new_tokens: 256
  do_sample: false

# Contrastive search
gptj:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
gptj_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
gptj_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
gptj_int8:
  max_new_tokens: 256
  do_sample: false

# Top-p sampling
gpt2:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Top-p sampling
gpt2_lora:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Top-p sampling
gpt2_lora_int8:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Top-p sampling
gpt2_int8:
  do_sample: true
  top_k: 0
  top_p: 0.92
  max_new_tokens: 256

# Contrastive search for GPT-OSS models (high reasoning capability)
gpt_oss_120b:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_120b_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_120b_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_120b_lora_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_120b_lora_kbit:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

# Contrastive search for GPT-OSS 20B models
gpt_oss_20b:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_20b_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_20b_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_20b_lora_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

gpt_oss_20b_lora_kbit:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

# Contrastive search
llama:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
llama_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama_lora_kbit:
  max_new_tokens: 256
  do_sample: false

# Contrastive search
llama2:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
llama2_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama2_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama2_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
llama2_lora_kbit:
  max_new_tokens: 256
  do_sample: false

# Greedy search
mamba:
  do_sample: false

# Contrastive search for MiniMaxM2
minimax_m2:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

minimax_m2_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

minimax_m2_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

minimax_m2_lora_int8:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

minimax_m2_lora_kbit:
  max_new_tokens: 512
  do_sample: false
  temperature: 0.1

# Contrastive search
qwen3_0_6b:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
qwen3_0_6b_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
qwen3_0_6b_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
qwen3_0_6b_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
qwen3_0_6b_lora_kbit:
  max_new_tokens: 256
  do_sample: false

# Contrastive search
opt:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Contrastive search
opt_lora:
  penalty_alpha: 0.6
  top_k: 4
  max_new_tokens: 256
  do_sample: false

# Greedy search
opt_lora_int8:
  max_new_tokens: 256
  do_sample: false

# Greedy search
opt_int8:
  max_new_tokens: 256
  do_sample: false
